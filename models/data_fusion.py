# models/data_fusion.py
import os
import zipfile
from pathlib import Path
import pandas as pd
import numpy as np
from datetime import datetime

RAW_BASE = Path("data/raw_data")
CMLRE_DIR = RAW_BASE / "cmlre" / "extracted"
WOD_DIR = RAW_BASE / "wod_oceanographic"
PROCESSED_DIR = Path("data/processed_data")
OUTPUT_CSV = PROCESSED_DIR / "fused_occurrence_oceanographic.csv"

# Ensure directories exist
def ensure_dirs():
    PROCESSED_DIR.mkdir(parents=True, exist_ok=True)

def load_cmlre_occurrences():
    """Load Darwin Core occurrence data"""
    print("‚úÖ Loading CMLRE occurrence data...")
    
    try:
        occ_file = next((p for p in CMLRE_DIR.glob("occurrence.txt")), None)
        if occ_file is None:
            raise FileNotFoundError("occurrence.txt not found")
            
        # Darwin Core is often tab-delimited
        df = pd.read_csv(occ_file, sep='\t', low_memory=False)
        
    except Exception as e:
        print(f"‚ö†Ô∏è Error loading occurrence data: {e}")
        print("‚ö†Ô∏è Creating synthetic occurrence data for demo...")
        
        # Create synthetic data
        species = ['Epinephelus marginatus', 'Thunnus albacares', 'Katsuwonus pelamis', 
                  'Coryphaena hippurus', 'Scomberomorus commerson']
        df = pd.DataFrame({
            'scientificName': np.random.choice(species, 1000),
            'decimalLatitude': np.random.uniform(8.0, 12.0, 1000),
            'decimalLongitude': np.random.uniform(72.0, 78.0, 1000),
            'eventDate': pd.date_range(start='1/1/2022', periods=1000)
        })
    
    # Standardize column names
    rename_map = {
        'decimalLatitude': 'latitude',
        'decimalLongitude': 'longitude',
        'eventDate': 'event_date',
        'scientificName': 'scientific_name'
    }
    
    for k, v in rename_map.items():
        if k in df.columns:
            df.rename(columns={k: v}, inplace=True)
    
    # Parse date
    if 'event_date' in df.columns:
        df['timestamp'] = pd.to_datetime(df['event_date'], errors='coerce')
    elif 'timestamp' not in df.columns:
        df['timestamp'] = pd.NaT
    
    # Filter invalid coordinates
    if {'latitude', 'longitude'}.issubset(df.columns):
        df = df[(df['latitude'].between(-90, 90)) & 
               (df['longitude'].between(-180, 180))]
    
    print(f"‚úÖ Processed {len(df)} occurrence records")
    return df

def load_wod_data():
    """Load World Ocean Database data"""
    print("‚úÖ Loading WOD oceanographic data...")
    
    try:
        # Try to load real WOD data
        wod_files = list(WOD_DIR.glob("*.csv"))
        if not wod_files:
            raise FileNotFoundError("No WOD CSV files found")
            
        dfs = []
        for f in wod_files:
            df = pd.read_csv(f)
            dfs.append(df)
        
        wod = pd.concat(dfs, ignore_index=True)
        
    except Exception as e:
        print(f"‚ö†Ô∏è Error loading WOD data: {e}")
        print("‚ö†Ô∏è Creating synthetic oceanographic data for demo...")
        
        # Create synthetic oceanographic data
        wod = pd.DataFrame({
            'latitude': np.random.uniform(8.0, 12.0, 2000),
            'longitude': np.random.uniform(72.0, 78.0, 2000),
            'timestamp': pd.date_range(start='1/1/2022', periods=2000),
            'temperature': np.random.uniform(20.0, 30.0, 2000),
            'salinity': np.random.uniform(33.0, 36.0, 2000),
            'depth': np.random.uniform(0, 200, 2000)
        })
    
    print(f"‚úÖ Processed {len(wod)} oceanographic records")
    return wod

def temporal_spatial_merge(occ, ocean, spatial_precision=2, time_freq='D'):
    """Merge occurrence and oceanographic data"""
    print("‚úÖ Merging datasets...")
    
    # For each dataframe
    for df in (occ, ocean):
        # Process timestamps
        if 'timestamp' in df.columns:
            df['timestamp'] = pd.to_datetime(df['timestamp'], errors='coerce')
            if pd.api.types.is_datetime64_any_dtype(df['timestamp']):
                df['timestamp_round'] = df['timestamp'].dt.floor(time_freq)
            else:
                df['timestamp_round'] = pd.NaT
        else:
            df['timestamp_round'] = pd.NaT
        
        # Process coordinates
        if 'latitude' in df.columns:
            df['lat_round'] = pd.to_numeric(df['latitude'], errors='coerce').round(spatial_precision)
        else:
            df['lat_round'] = np.nan
            
        if 'longitude' in df.columns:
            df['lon_round'] = pd.to_numeric(df['longitude'], errors='coerce').round(spatial_precision)
        else:
            df['lon_round'] = np.nan
    
    # Merge on rounded coordinates and time
    merged = pd.merge(
        occ,
        ocean,
        on=['lat_round', 'lon_round', 'timestamp_round'],
        how='left',
        suffixes=('_occ', '_ocean')
    )
    
    print(f"‚úÖ Created {len(merged)} merged records")
    return merged

def post_merge_cleanup(df, env_cols=('temperature', 'salinity', 'depth')):
    """Clean up after merge"""
    print("‚úÖ Post-merge cleanup...")
    
    # Remove duplicates
    df = df.drop_duplicates()
    
    # Ensure we have the expected columns
    essential_cols = ['scientific_name', 'latitude', 'longitude', 'timestamp']
    for col in essential_cols:
        if col not in df.columns:
            df[col] = np.nan
    
    # Keep only rows with the essential data
    df = df.dropna(subset=['scientific_name', 'latitude', 'longitude'])
    
    print(f"‚úÖ Final dataset: {len(df)} records")
    return df

def main():
    """Main function"""
    print("üåä Ocean Data Fusion Process üåä")
    print("==============================")
    
    # Ensure directories exist
    ensure_dirs()
    
    # Load datasets
    occ = load_cmlre_occurrences()
    wod = load_wod_data()
    
    # Merge datasets
    fused = temporal_spatial_merge(occ, wod)
    
    # Post-processing
    fused = post_merge_cleanup(fused)
    
    # Save output
    print(f"üíæ Saving fused dataset to {OUTPUT_CSV}")
    fused.to_csv(OUTPUT_CSV, index=False)
    
    print("üéâ Data fusion complete!")

if __name__ == "__main__":
    main()